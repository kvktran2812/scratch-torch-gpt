{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d451318-d54a-4ca6-b1d8-20384db92c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from script.gpt_utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4c412-f439-4782-950a-a6b1c6a01b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read original file\n",
    "with open('data/truyen_kieu_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove special characters throughout the text\n",
    "text = re.sub(r\"[:;!.,?\\\\'\\\"]\", '', text)\n",
    "\n",
    "# Remove the last character if it's not a letter or number\n",
    "text = re.sub(r'[^a-zA-Z0-9]$', '', text)\n",
    "\n",
    "# Save to a new file\n",
    "with open('data/truyen_kieu.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Cleaned text saved to 'data/truyen_kieu.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea2ceb0-da21-4446-b24d-0c9755838820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 121\n",
      "Number of characters: 101140\n"
     ]
    }
   ],
   "source": [
    "# Preparation phase\n",
    "chars, text, vocab_size = load_truyen_kieu_dataset(\"data/truyen_kieu.txt\")\n",
    "encoder, decoder = load_encoder_decoder(chars)\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "train_data, val_data = split_data(data, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2136fc3e-d113-4c72-9fe3-3acfcf4f4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_size, in_channels, n_heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        self.embedding_size = embedding_size\n",
    "        self.in_channels = in_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.head_size = embedding_size // n_heads\n",
    "        \n",
    "        self.c_attn = nn.Linear(embedding_size, embedding_size * 3)\n",
    "        self.proj = nn.Linear(embedding_size, embedding_size)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.ln_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q, k, v = self.c_attn(x).split(self.embedding_size, 2)\n",
    "        \n",
    "        q = q.view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        if self.flash:\n",
    "            value = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            attn = q @ k.transpose(-2, -1) * (1 / math.sqrt(self.head_size))\n",
    "            attn = F.softmax(attn, dim=-1)\n",
    "            attn = self.attn_dropout(attn)\n",
    "            value = attn @ v\n",
    "        value = value.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        value = self.proj(value)\n",
    "        value = self.ln_dropout(value)\n",
    "        return value\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_channels, factor, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1 = nn.Linear(in_channels, in_channels * factor)\n",
    "        self.ln2 = nn.Linear(in_channels * factor, in_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.ln1(x))\n",
    "        x = self.ln2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, embedding_size, n_heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        head_size = embedding_size // n_heads\n",
    "        self.multi_head_attn = MultiHeadAttention(embedding_size, in_channels, n_heads, dropout)\n",
    "        self.ffwd = FeedForward(embedding_size, 4, dropout)\n",
    "        self.ln1 = nn.LayerNorm(embedding_size)\n",
    "        self.ln2 = nn.LayerNorm(embedding_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.multi_head_attn(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, in_channels, vocab_size, embedding_size, n_heads, n_layers, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.position_embedding_table = nn.Embedding(in_channels, embedding_size)\n",
    "        self.blocks = nn.Sequential(*[Block(in_channels, embedding_size, n_heads) for _ in range(n_layers)])\n",
    "        self.ln_f = nn.LayerNorm(embedding_size)\n",
    "        self.lm_head = nn.Linear(embedding_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * n_layers))\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        device = x.device\n",
    "        B,T = x.size()\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=device)\n",
    "        token_embedding = self.token_embedding_table(x)\n",
    "        pos_embedding = self.position_embedding_table(pos)\n",
    "        \n",
    "        x = self.dropout(token_embedding + pos_embedding)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            loss = None\n",
    "        return logits, loss\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, block_size: int = 32, temperature=1.0, top_k=None): \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0aa4eac-a66c-4168-8dbe-ea6c09df5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, val_data, device: str = 'cpu', n_iters: int = 100):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(n_iters)\n",
    "    for k in range(n_iters):\n",
    "        x_val, y_val = get_batch(val_data)\n",
    "        x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "        logits, loss = model(x_val, y_val)\n",
    "        losses[k] = loss.item()\n",
    "    model.train()\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6832d24-0bb3-43ae-8cb2-dfac3873ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, \n",
    "    optimizer, \n",
    "    device, \n",
    "    train_data,\n",
    "    val_data,\n",
    "    n_steps: int = 1000, \n",
    "    train_iter: int = 100, \n",
    "    eval_iter: int = 100, \n",
    "    total_eval: int = 100, \n",
    "    save_checkpoint: int = 100, \n",
    "    save_dir: str = \"checkpoints\"\n",
    "):\n",
    "    # Preparation\n",
    "    model.to(device)\n",
    "    loss_history = []\n",
    "    save = 1\n",
    "\n",
    "    # Check if save dir valid\n",
    "    if not os.path.exists(save_dir):\n",
    "        print(\"Directory not exist, creating directory...\")\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Directory {save_dir} created\")\n",
    "    else:\n",
    "        print(f\"Directory {save_dir} exists\")\n",
    "    print(\"Start training...\")\n",
    "    \n",
    "    for step  in range(n_steps):\n",
    "        model.train()\n",
    "        x_train, y_train = get_batch(train_data)\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "        logits, loss = model(x_train, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        # Evaluation\n",
    "        if step != 0:\n",
    "            if step % train_iter == 0:\n",
    "                avg_loss = sum(loss_history[-train_iter:]) / train_iter  # Compute average over last eval_iter steps\n",
    "                print(f\"Step {step}: Average Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "            if step % eval_iter == 0:\n",
    "                eval_loss = eval(model, val_data, device, total_eval)\n",
    "                print(f\"***Eval: {eval_loss:.4f}\")\n",
    "    \n",
    "            if step % save_checkpoint == 0:\n",
    "                torch.save(model.state_dict(), f\"{save_dir}/checkpoint_{int(save)}.pth\")\n",
    "                save += 1\n",
    "\n",
    "    # Final eval:\n",
    "    eval_loss = eval(model, val_data, device, total_eval)\n",
    "    print(\"*\" * 10)\n",
    "    avg_loss = sum(loss_history) / n_steps\n",
    "    print(f\"Final eval --- Step: {n_steps} - Training Loss: {avg_loss:.4f} - Eval Loss: {eval_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"{save_dir}/checkpoint_final.pth\")\n",
    "\n",
    "    return loss_history, eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b221ac6e-b5f7-4c8e-bbf0-753e1bab50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory checkpoints exists\n",
      "Start training...\n",
      "Step 100: Average Loss = 3.0137\n",
      "***Eval: 2.3585\n",
      "Step 200: Average Loss = 2.1331\n",
      "***Eval: 2.0541\n",
      "Step 300: Average Loss = 1.9053\n",
      "***Eval: 1.8421\n",
      "Step 400: Average Loss = 1.8084\n",
      "***Eval: 1.7967\n",
      "Step 500: Average Loss = 1.7473\n",
      "***Eval: 1.7694\n",
      "Step 600: Average Loss = 1.6986\n",
      "***Eval: 1.7781\n",
      "Step 700: Average Loss = 1.6518\n",
      "***Eval: 1.7621\n",
      "Step 800: Average Loss = 1.6107\n",
      "***Eval: 1.7126\n",
      "Step 900: Average Loss = 1.5548\n",
      "***Eval: 1.6712\n",
      "Step 1000: Average Loss = 1.5050\n",
      "***Eval: 1.7941\n",
      "Step 1100: Average Loss = 1.4307\n",
      "***Eval: 1.7807\n",
      "**********\n",
      "Final eval --- Step: 1200 - Training Loss: 1.7879 - Eval Loss: 1.7809\n"
     ]
    }
   ],
   "source": [
    "# hyperparamters \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_steps = 1200\n",
    "eval_iter = 100\n",
    "train_iter = 100\n",
    "total_eval = 100\n",
    "\n",
    "model = GPT(512, vocab_size, 512, 32, 6)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004)\n",
    "\n",
    "\n",
    "loss_history, eval_loss = train(\n",
    "    model, \n",
    "    optimizer, \n",
    "    device,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    n_steps=n_steps,\n",
    "    train_iter=train_iter,\n",
    "    eval_iter=eval_iter,\n",
    "    total_eval=total_eval,\n",
    "    save_checkpoint=100,\n",
    "    save_dir=\"checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbec6b91-689a-431d-9f6e-dbe7976bf37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ành đường ai ráng tình quỉ can\n",
      "Hồng đã quấn kiếp với cờ dài\n",
      "Thoảng dương thiệt mặt ngày mời\n",
      "Sầu bèa vửa đảoến chiêm m \n",
      "Trhưa Hết hẹp mừng mới là đầy sau\n",
      "Lẫu sao như nước sốt bao\n",
      "Hẳn sao vực nàng trưởn"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nành đường ai ráng tình quỉ can\\nHồng đã quấn kiếp với cờ dài\\nThoảng dương thiệt mặt ngày mời\\nSầu bèa vửa đảoến chiêm m \\nTrhưa Hết hẹp mừng mới là đầy sau\\nLẫu sao như nước sốt bao\\nHẳn sao vực nàng trưởn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beautiful_print(model, decoder, 200, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af18845-ba86-402b-bcf2-0f66eab9a11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
