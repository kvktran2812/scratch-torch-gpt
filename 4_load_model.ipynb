{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f535e6bc-b4e8-4e76-9b5c-b5707ef90956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from script.gpt import GPT\n",
    "from script.gpt_utils import *\n",
    "from safetensors.torch import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adad48a-371a-4aac-8c6d-857e027e37d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 121\n",
      "Number of characters: 101140\n"
     ]
    }
   ],
   "source": [
    "PATH = \"checkpoints/checkpoint_final.pth\"\n",
    "\n",
    "# Preparation phase\n",
    "chars, text, vocab_size = load_truyen_kieu_dataset(\"data/truyen_kieu.txt\")\n",
    "encoder, decoder = load_encoder_decoder(chars)\n",
    "\n",
    "model = GPT(512, vocab_size, 512, 32, 6)\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# Save model as safetensors\n",
    "save_file(model.state_dict(), \"checkpoints/truyen_kieu_gpt.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8a4e8-729d-447f-9ffd-eb942af0ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rằng Tôi gặp cơn nhờn khấu khẩn mưa ngảy ngao\n",
      "Khua chưa chung mà trạng rang chầu\n",
      "Đã trươi dễi chiếng dương mày\n",
      "Tiếc kiác b"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "beautiful_print(model, decoder, 200, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9daab-ff19-43c9-b087-95e0b39e54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, num_sentences=4, device=\"cuda\", temperature=1.0, top_k=None, block_size=128):\n",
    "    # special_chars = ['\\n']\n",
    "    word_counts = [6, 8]  # Alternate between 6 and 8 words\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    sentences = []\n",
    "\n",
    "    # Convert forbidden characters to token indices\n",
    "    # special_char_indices = torch.tensor([encoder(ch) for ch in special_chars], device=device)\n",
    "\n",
    "    model.eval()\n",
    "    for i in range(num_sentences):\n",
    "        idx = context\n",
    "        word_count = word_counts[i % 2]  # Alternate sentence lengths\n",
    "        char_count = 0\n",
    "        current_word_count = 0\n",
    "        sentence = \"\"\n",
    "\n",
    "        while current_word_count < word_count:\n",
    "            idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
    "            logits, _ = model(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "\n",
    "            # logits[:, special_char_indices] = -float('Inf')\n",
    "            \n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            char = decoder([idx_next.item()])\n",
    "\n",
    "            if char == \"\\n\":\n",
    "                continue\n",
    "\n",
    "            # Count words based on spaces\n",
    "            if char == \" \" and char_count > 1:\n",
    "                current_word_count += 1\n",
    "\n",
    "            sentence += char\n",
    "            char_count += 1\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        # append new line here:\n",
    "        idx = torch.cat((idx, torch.zeros((1, 1), device='cuda:0', dtype=torch.long)), dim=1)\n",
    "        sentences.append(sentence.strip())\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327793e-9b69-40ac-9360-bf1ddfebbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6d306-3bed-48fc-8afb-823e8b874f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
