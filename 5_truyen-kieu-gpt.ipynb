{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5f2c1d-22da-4555-9423-932b00d96452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x251ef0a7130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c940ccfe-573e-47a1-8a09-2f4d394d7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 129\n",
      "Number of characters: 104804\n"
     ]
    }
   ],
   "source": [
    "with open('truyen_kieu_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Number of characters:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c574928c-0df6-435f-bf17-cb1d0bf39f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 39, 100, 50, 1, 49, 38, 80, 42, 1, 41, 86, 43, 1, 37, 39, 114, 1, 49, 47, 82, 112, 34, 1, 76, 61, 43]\n",
      "Kiểu thơm lần giở trước đèn\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"Kiểu thơm lần giở trước đèn\"))\n",
    "print(decode(encode(\"Kiểu thơm lần giở trước đèn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5033cd42-7692-4cda-bba8-d7dd8669fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f22043-0390-4c53-bf85-68004577ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 2500\n",
    "eval_interval = 100\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 256\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5b5bbe-8c2f-4585-89a7-4e4765a39528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "    \n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "    \n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v \n",
    "        return out\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.multihead = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.multihead], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads, n_embd):\n",
    "        super().__init__()\n",
    "        self.multihead = MultiHead(n_heads, n_embd//n_heads)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.multihead(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8903067-c0a6-490a-a9a2-16728f80ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_head, n_embd) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.positional_embedding(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb # B, T, C\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x) # B, T, vocab_size\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_token):\n",
    "        for _ in range(max_new_token):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc652aef-c91f-4f8e-872a-1d510b7d8b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9947, val loss 4.9969\n",
      "step 100: train loss 2.2937, val loss 2.2822\n",
      "step 200: train loss 2.2094, val loss 2.2043\n",
      "step 300: train loss 2.1705, val loss 2.1666\n",
      "step 400: train loss 2.1293, val loss 2.1337\n",
      "step 500: train loss 2.0439, val loss 2.0530\n",
      "step 600: train loss 1.9381, val loss 1.9477\n",
      "step 700: train loss 1.8612, val loss 1.8754\n",
      "step 800: train loss 1.8019, val loss 1.8192\n",
      "step 900: train loss 1.7458, val loss 1.7600\n",
      "step 1000: train loss 1.6989, val loss 1.7241\n",
      "step 1100: train loss 1.6577, val loss 1.6896\n",
      "step 1200: train loss 1.6273, val loss 1.6693\n",
      "step 1300: train loss 1.5926, val loss 1.6449\n",
      "step 1400: train loss 1.5644, val loss 1.6259\n",
      "step 1500: train loss 1.5420, val loss 1.6187\n",
      "step 1600: train loss 1.5156, val loss 1.6097\n",
      "step 1700: train loss 1.4828, val loss 1.5903\n",
      "step 1800: train loss 1.4555, val loss 1.5840\n",
      "step 1900: train loss 1.4279, val loss 1.5753\n",
      "step 2000: train loss 1.4045, val loss 1.5741\n",
      "step 2100: train loss 1.3744, val loss 1.5671\n",
      "step 2200: train loss 1.3425, val loss 1.5566\n",
      "step 2300: train loss 1.3150, val loss 1.5666\n",
      "step 2400: train loss 1.2814, val loss 1.5688\n",
      "step 2499: train loss 1.2542, val loss 1.5728\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e5ba5a-e837-4af3-86d0-89522348d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nành sao lên xuân lại tiền quì,\n",
      "Thoắt càng trông kéo trả dầu dặm nhg.\n",
      "Vực tử các đồng đán tòng,\n",
      "Bấy giờ ngọn bóng như trôn hoa.\n",
      "Cạn Tương Khí nh nức trăm,\n",
      "Lòng đàm sắc làm khuyanh Kiều ngày .\n",
      "Tích nào câu hại ượn như hay,\n",
      "Họa quì cây lại lầy tia có chăn .\n",
      "Chư hiều ngảnh ăn Tiểu tróc muông,\n",
      "Xao thơ một vắng chàng thẹn đêm vàng.\n",
      "Rằng: Tiếng Vi dặm tội trường,\n",
      "Thân bàn eo khán quyết nhàng tôi .\n",
      "Đem thay nước bên trả chăng,\n",
      "Lện thương cánh cái thừa bên chưa.\n",
      "Bỗng chiệt thuở lễ đâ,\n",
      "Đầy thân hỏi dễ bắt ngơ cho gì .\n",
      "Oan mình bể ta khỏi dàu,\n",
      "Những gười, xinh vạt bất chuộc va !\n",
      "Xăm đi chấp càng đá điều,\n",
      "Ngập thét, ngảng giếp cỏ gì lai.\n",
      "Nàng nhờn cũng bậm người,\n",
      "Mà hỏi ê cửa cũng ngừn dài thá cho.\n",
      "Tường sinh sởngẫm đôn ý nhà,\n",
      "Hoa rủ dôn cũng hoài hoa nhà nết sầu.\n",
      "Sinh sinh nành típ áo dồi,\n",
      "Trên điều đà ngiọt phận kiều hằng !\n",
      "Từ công, nhẩn đã giữ vỏ tường,\n",
      "Nàng quen viện tái nên,\n",
      "Đem tên mio thảng ai đã chi nàng !\n",
      "Đã giay khi vào,\n",
      "Cướt triên Thúc liềm họa êm tình.\n",
      "Nơi suyên tót thiểu thấp dài nhi,\n",
      "Xót khi lại tình giáo xin túc xinh kinh .\n",
      "Ngày thông ngại gốc nói vui vầng.\n",
      "Trộn ranh danh gửi vàng việt lần gái ninh,\n",
      "Tần gầm phói nànất biết phải hanh xong.\n",
      "Gình thuen ngựa, mình tiểu lyết sao.\n",
      "Những lày biết nở gúc bài,\n",
      "Máu việnh việt như lòễ ướt suôn bề,\n",
      "Xem song đầu, bèo ngọn thực bốn nhà chia.\n",
      "Trong càn quen thẩn gái đường hoa,\n",
      "Tiền xa có thai phần mày chia !\n",
      "Cũng miều tuyết kín giờ,\n",
      "Đã biết xa nh máu trăng gió tang hang.\n",
      "Đốt vàng gió một gất mù đừang,\n",
      "Thú phậu bàn hại nàn.\n",
      "Dặm ngày đã vẻ một lản mưuôi ?\n",
      "Nao rúc đá tiếng nhân thân,\n",
      "Một bè vội gần lại thơm han.\n",
      "Dường tơ lãy ngỏ ấy già,\n",
      "Phải khuyệt thuiệt trở về đâu lân.\n",
      "Đào thay kể thân tríp !\n",
      "ý thôi lỡ đã trình, lá sai .\n",
      "Này càng ra chi đbể lộn phong,\n",
      "Vô đầu giãn đoái trác Duyên liều duyên quân.\n",
      "Báo chẳng trầu trọng lại hai,\n",
      "Dạy ngừng thì với chiệp cam cho ?\n",
      "Xót lòng chọng biết bao đài,\n",
      "ầm sén phen mình khó dư làm vắng phẩn xa!\n",
      "Sang thư sát sinh già,\n",
      "Thật lương vẹn, lẻnh hùm hoa giang thương .\n",
      "Chung này Vân cửa đượng qua nhi,\n",
      "V\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_token=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cc332-bc53-43a1-a469-802fb0ba0fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
